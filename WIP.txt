data, params = cls._load_from_file(load_path, custom_objects=custom_objects)

model = cls(policy=data["policy"], env=None, _init_setup_model=False)
model -> OffPolicyRLModel(BaseRLModel)

model.__dict__.update(data)
model.__dict__.update(kwargs)
model.set_env(env)

model.setup_model()
->
    <Algorithms>
    within setup_model
        1. if to modify input:
            Need to fix:
            - assertion within set_env : base_class
                -> observation space / action space
            - self.env.observation_space when initializing self.policy (self.policy_tf & self.target_policy)
                within sac.policies.py: feedforwardpolicy -> sacpolicy -> common.policies.py: basepolicy

        2. if to modify model:
            Need to fix:
            - make_actor / make_critics <maybe layer size should be sub as args here!!>
    
    <Guess>
        1. input ph for policy should be made with original data
        2. add additional layers alongside with the premade model
            -> additional ph / additional hidden layers
            -> for ph -> maybe concat?
        3. load existing parameters and init randomly for those are not within the parameters

    <Qs>
        1. Should value network also be changed?
        


model.load_parameters(params)
return model


