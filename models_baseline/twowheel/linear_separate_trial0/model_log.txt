Layers:
	policy:	[512, 256, 256]
	value:	[512, 256, 256]

trial:		0
action:		linear
tolerance:		0.1
total time steps:		50000000
n_robots:		1
n_targets:		1
episode_length:		2000
reward_method:		target
observation_method:		absolute
Additional Info:		Reset from random initial pos
                        		Agent rotates a bit less
                        		Target does not stay in position
                        		shallower network
                        		Positive reward
                        		Initial pose a bit inward
                        		PPO MPI
                        		using tanh to squash action
                        		learning_rate: 5e-5, gamma:0.99, nminibatches: 256, cliprange: 0.02
                        		Beta policy test
