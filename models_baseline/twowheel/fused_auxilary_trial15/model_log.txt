trial:		15
action:		fused
layers:		None
tolerance:		0.1
total time steps:		10000000
n_robots:		1
n_targets:		1
episode_length:		2000
reward_method:		target
observation_method:		absolute
batch_size:		8
Additional Info:		0.01* scaled rewards + linear prim trained with 0.01* scaled reward
                     		log_std_MCP clipped within the MCP module
                     		Does applying tanh + log_std clipping @ primitive side take effect?
                     		No squashing @ MCP
